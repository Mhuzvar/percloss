{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Overview of Perceptually Relevant Metrics of Audio Similarity for Potential Use as Loss In Training Neural Networks\n",
    "\n",
    "There are several areas that need thorough exploration:\n",
    "- conventional loss functions\n",
    "   - equipped with some modification to improve their perceptual relevance\n",
    "   - like pre-emphasis\n",
    "- complex perception focused metrics\n",
    "   - mostly focused on quality assessment\n",
    "   - may need some modification as well\n",
    "- trained models\n",
    "   - least \"safe\" method but likely best performing *as long as the inputs are similar to training dataset*\n",
    "\n",
    "General notes from the literature:\n",
    "\n",
    "- Amos Tversky researched similarity, perception, and categorization from psychology point of view. He noted human perception does not satisfy the definition of a euclidean metric [[1]](#references).\n",
    "- Large portion of \"music similarity\" research focuses on clustering music with the aim of content delivery optimization [[1]](#references).\n",
    "- MFCC based distance may be helpful [[1]](#references) (not directly mentioned) and there should be a way to make mel-cepstral distance differentiable [[2]](#references).\n",
    "- \n",
    "\n",
    "Personal comments:\n",
    "\n",
    "- Before settling for any similarity metric we first need to decide, whether the compared signals have to be produced with the same input signal\n",
    "   - A guitar player may be able to tell if two systems are similar (or the same) even when hearing two different riffs played through them\n",
    "   - Metric which does not require the same input signals on both compared systems may be helpful in some cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional Loss\n",
    "\n",
    "- Pros\n",
    "   - easy to use\n",
    "   - easy to represent\n",
    "   - works the same regardless of data\n",
    "   - computationally not difficult\n",
    "- Cons\n",
    "   - perceptually irrelevant\n",
    "\n",
    "Conventional loss, such as MSE, might be better suited for the task at hand when improved with some form of pre-emphasis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Perception Focused Metrics\n",
    "\n",
    "- Pros\n",
    "   - perceptually relevant\n",
    "   - works the same regardless of data (mosly [[3]](#references))\n",
    "- Cons\n",
    "   - may not be easy to use\n",
    "   - may not be easy to represent\n",
    "   - can be computationally difficult\n",
    "\n",
    "### Notes From Literature\n",
    "\n",
    "- PEMO-Q [[3]](#references)\n",
    "   - PEMO-Q was created for lossy compression evaluation [[3]](#references).\n",
    "   - Attempts to answer the problem of doubts about PEAQ being a realistic and valid model of general auditory perception [[3]](#references).\n",
    "   - Auditory model\n",
    "      - The signals are preprocessed in a way that may not be suitable for our problem [[3]](#references).\n",
    "      - After preprocessing, the signals are transformed into \"internal representation\" using an auditory signal processing model [[3]](#references).\n",
    "         - 35-band gammatone filterbank (basilar membrane characteristics) with each band then processed individually\n",
    "         - half-wave rectification and low pass filter at 1 kHz (transformation of mechanical oscillations to neural firing rates of the inner haircells)\n",
    "         - absolute hearing threshold determined from assumed maximum signal input\n",
    "         - sequence of five nonliear feedback loops\n",
    "            - dividing element and a low-pass (RC)\n",
    "            - input is divided by low passed output\n",
    "         - linear modulation filterbank, the most significant diference rom previous work\n",
    "            - a simplified version of PEMO-Q replaces this part with modulation-low-pass version of the auditory model (less accurate but less computationally difficult)\n",
    "      - Lastly, cognitive effects are modeled in post-processing stage [[3]](#references).\n",
    "   - Each channel of the outputs of auditory model are then cross correlated, which (after a weighed sum) gives a perceptual quality measure called PSM [[3]](#references).\n",
    "   - PEMO-Q also defines a second, more detailed (in time) measure called PSM<sub>t</sub>, which is likely not of significance for our work [[3]](#references).\n",
    "   - When using the computationally less demanding version, PEMO-Q is signal dependent [[3]](#references).\n",
    "   - The correlation between the PSM and subjective ratings is higher than between PSM<sub>t</sub> and subjective ratings as long as only one type of signals is studied [[3]](#references).\n",
    "   - According to the paper, it should be applicable more generally, but is not suitable for predicting impact of linear systems [[3]](#references).\n",
    "\n",
    "- ViSQOLAudio [[4]](#references)\n",
    "   - VISQOL is originally a speech quality model that was later modified to function as a method of perceptual evaluation of lossy compression [[4]](#references).\n",
    "   - VISQOLAudio is an improved VISQOL (improed in respect to lossy compression evaluation) [[4]](#references).\n",
    "   - The introduction of machine learning and output of MOS [[4]](#references) may mean original VISQOL could be better for our use case.\n",
    "   - According to authors of the papers, VISQOLAudio is the first free and open source audio quality metric with accuracy comparable to proprietary metrics used in the industry [[4]](#references).\n",
    "   - \n",
    "   - pg. 694 col. 1, sec. II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trained Models\n",
    "\n",
    "- Pros\n",
    "   - potential for best performance\n",
    "   - should be easy to use\n",
    "- Cons\n",
    "   - virtually impossible to represent\n",
    "   - no guarantee of performance on unknown data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [1] [A Large-Scale Evaluation of Acoustic and Subjective Music-Similarity Measures](https://www.jstor.org/stable/3681827)\n",
    "- [2] [Embedding a Differentiable MEL-Cepstral Synthesis Filter to a Neural Speech Synthesis System](https://arxiv.org/pdf/2211.11222)\n",
    "- [3] [PEMO-Qâ€”A New Method for Objective Audio Quality Assessment Using a Model of Auditory Perception](https://ieeexplore.ieee.org/document/1709880)\n",
    "- [4] [Objective Assessment of Perceptual Audio Quality Using ViSQOLAudio](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7940042)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources to go through\n",
    "\n",
    "- [a] A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences\n",
    "  - https://arxiv.org/abs/2001.04460\n",
    "  - neural network trained on a large dataset of crowdsourced human judgements\n",
    "  - implemented in TesorFlow at: https://github.com/pranaymanocha/PerceptualAudio?tab=readme-ov-file\n",
    "- [b] Auditory Feature-based Perceptual Distance\n",
    "  - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10925319/\n",
    "  - not reviewed yet\n",
    "  - comparison of several options\n",
    "- [c] Audio retrieval based on perceptual similarity\n",
    "  - https://ieeexplore.ieee.org/document/7014580\n",
    "- [d] Modeling Perceptual Similarity of Audio Signals for Blind Source Separation Evaluation\n",
    "  - https://www.researchgate.net/publication/220848024_Modeling_Perceptual_Similarity_of_Audio_Signals_for_Blind_Source_Separation_Evaluation\n",
    "- [e] A Similarity Measure for Automatic Audio Classification\n",
    "  - likely not too useful\n",
    "  - https://cdn.aaai.org/Symposia/Spring/1997/SS-97-03/SS97-03-001.pdf\n",
    "- [f] An Objective Metric of Human Subjective Audio Quality Optimized for a Wide Range of Audio Fidelities\n",
    "  - https://ieeexplore.ieee.org/abstract/document/4358089\n",
    "- [g] Music Popularity: Metrics, Characteristics, and Audio-Based Prediction\n",
    "  - https://ieeexplore.ieee.org/abstract/document/8327835"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help From Others\n",
    "\n",
    "### Metody hodnoceni zvuku od Vaska\n",
    "\n",
    "\n",
    ">Ahoj,\n",
    ">\n",
    ">tady jsou nejake linky na systemy hodnoceni kvality zvuku, ktere by se mohly dat aplikovat na Tvuj problem.\n",
    ">\n",
    ">https://github.com/google/visqol Tohle je system, ktery je podle clanku obstojny a asi jeden z poslednich, o kterych vim. https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7940042\n",
    ">\n",
    ">Tohle je starsi system, ktery ma jednodussi impementaci, takze mozna pro zacatek by byl rozumnejsi https://ieeexplore.ieee.org/document/1709880\n",
    ">\n",
    ">Obecne ty systemy vyuzivaji banky filtru zvanou gammatone filterbank, ktera se da najit treba tady https://amtoolbox.org/models.php Ten zbytek algoritmu by se mel taky dat najit v tom toolboxu a vyhodnoceni uz je pomoci rovnic, co se daji snadno implementovat.\n",
    ">\n",
    ">\n",
    ">Ja sam jsem nikdy prakticky ty systemy nepouzil. Prevzal jsem rozhodovaci cast z PEMO-Q pro jeden konferencni prispevek. Tam jsem nahradil banku filtru necim, co by melo byt vernejsi funkci sluchu, ale zase je to vypocetne nesrovnale narocnejsi. Takze bych sam spise zacal od tech zavedenych signal processingovych postupu v odkazech. Kdyby jsi o funkci sluchu chtel vedet vic, pak mam v doktorske etape predmet.\n",
    ">\n",
    ">Vasek\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
